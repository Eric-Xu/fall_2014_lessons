{
 "metadata": {
  "name": "",
  "signature": "sha256:c2564745e1be5890bf04a97123173892eb5db1d4b2e57a74d8bc02c36686d9a4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Data Explor06\n",
      "##Mark Holt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "#Image(url='http://upload.wikimedia.org/wikipedia/en/1/1c/LightningBoltSkull.gif')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#http://www.cs.cmu.edu/~./gdead/setlists.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import string\n",
      "import re\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "from sets import Set\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import MultinomialNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df = pd.read_csv(\"GDsetlists.csv\")\n",
      "df = pd.read_csv(\"https://raw.githubusercontent.com/gads14-nyc/fall_2014_lessons/master/dataexplor06/GDsetlists.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "kS (below) was an independent list of GD songs that I found on the Internet. Used it to figure out what the names of some of the songs actually were."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#kS = pd.read_csv(\"gDeadSongList.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#kS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Comments:\n",
      "\n",
      "I did not do the data scraping part of this Explor. \n",
      "\n",
      "This is the dataset provided.\n",
      "\n",
      "Initial observations indicate it is pretty noisey. There are 2 columns for \"All Along the Watchtower\" for example. There is an unknown set list, and columns with \"?????\", and \"Comments...\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "&lt;class 'pandas.core.frame.DataFrame'&gt;\n",
        "Int64Index: 5 entries, 0 to 4\n",
        "Columns: 433 entries, 26 Miles to year\n",
        "dtypes: bool(432), int64(1)\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 5 entries, 0 to 4\n",
        "Columns: 433 entries, 26 Miles to year\n",
        "dtypes: bool(432), int64(1)"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###What years do we have?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print df['year'].max()\n",
      "print df['year'].min()\n",
      "print df['year'].mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1992\n",
        "1972\n",
        "1982.43484521\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Do some pre-processing to clean up the dataset a bit\n",
      "\n",
      "Going to try and clean up the song titles.\n",
      "Convert to lowercase.\n",
      "Remove punctuation.\n",
      "Remove the word \"jam\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lcCols = list(df.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0,len(lcCols)):\n",
      "    lcCols[i] = lcCols[i].lower()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'[\\',.!\\[\\]\\>]*'\n",
      "for i in range(0,len(lcCols)):\n",
      "    lcCols[i] = re.sub(pattern, '', lcCols[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patternB = r' jam'\n",
      "for i in range(0,len(lcCols)):\n",
      "    lcCols[i] = re.sub(patternB, '', lcCols[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The printout of the song names reveals multiple columns for certain songs. Usually because a song has a minor mispelling."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for i in range(0,len(lcCols)):\n",
      "#    print i, lcCols[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create some functions to quanitify the mis-spellings so that we can automatically detect them and correct them. This means eliminating 2 columns and replacing them with a single merged column (the union of the two original columns)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def perDiff(a, b):\n",
      "    sameCount = 0\n",
      "    diffCount = 0\n",
      "    aL = len(a)\n",
      "    bL = len(b)\n",
      "    \n",
      "    if aL > bL:\n",
      "        diffCount = aL - bL\n",
      "        n = bL\n",
      "    else:\n",
      "        diffCount = bL - aL\n",
      "        n = aL\n",
      "    for i in range(0,n):\n",
      "        if a[i] == b[i]:\n",
      "            sameCount = sameCount + 1\n",
      "        else:\n",
      "            diffCount = diffCount + 1\n",
      "    return(diffCount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#This is nicely written.  Using list() and zip there would be no need\n",
      "#to even look at string length since if one were longer it'd be truncated.\n",
      "h=\"wdawdaw\"\n",
      "y=\"wwdawdaww\"\n",
      "print list(h)\n",
      "print zip(list(h),list(y))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['w', 'd', 'a', 'w', 'd', 'a', 'w']\n",
        "[('w', 'w'), ('d', 'w'), ('a', 'd'), ('w', 'a'), ('d', 'w'), ('a', 'd'), ('w', 'a')]\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Well done, Mark!  This is a creative and elegant solution to string similarity\n",
      "#without the problem of having one different character misalign two otherwise \n",
      "#similar strings.\n",
      "\n",
      "def wordDiff(a, b):\n",
      "    diffCount = 0\n",
      "    s1 = a.split(' ')\n",
      "    s2 = b.split(' ')\n",
      "    #print s1\n",
      "    #print s2\n",
      "    aS = len(s1)\n",
      "    bS = len(s2)      \n",
      "    #print aS, bS\n",
      "    if aS > bS:\n",
      "        diffCount = 10 * (aS - bS)\n",
      "        nn = bS\n",
      "    else:\n",
      "        diffCount = 10 * (bS - aS)\n",
      "        nn = aS\n",
      "    #print \"nn is \" , nn\n",
      "    for i in range(0, nn):\n",
      "            if(s1[i]!=s2[i]):\n",
      "                #print s1[i], s2[i]\n",
      "                diffCount = diffCount + perDiff(s1[i], s2[i])\n",
      "    return diffCount"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A couple of small tests:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lcCols[146]\n",
      "print lcCols[147]\n",
      "wordDiff(lcCols[146], lcCols[147])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "goin down the road feelin bad\n",
        "goin down the road feeling bad\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lcCols[1]\n",
      "print lcCols[2]\n",
      "wordDiff(lcCols[1], lcCols[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "from the heart of me\n",
        "?????\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 91,
       "text": [
        "45"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run this on the song list as represented by the column names.\n",
      "\n",
      "The function returns combinations of column indices for pairs of columns that need to be condensed into a single column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compDiffWords(lcCols):\n",
      "    colar = []\n",
      "    for i in range(0,len(lcCols)):\n",
      "        for j in range(0,len(lcCols)):\n",
      "            if(i != j):\n",
      "                nn = wordDiff(lcCols[i],lcCols[j])\n",
      "                if nn < 2:\n",
      "                    if(i<j):\n",
      "                        b=(i,j)\n",
      "                    else:\n",
      "                        b=(j,i)\n",
      "                    if(b in colar):\n",
      "                        k=0\n",
      "                    else:\n",
      "                        colar.append(b)\n",
      "                    #print i, j, lcCols[i], \"  :  \", lcCols[j], nn \n",
      "    return colar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gg=compDiffWords(lcCols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(gg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47\n"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gg[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "[(7, 8), (29, 31), (40, 41), (44, 45), (56, 57)]"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfA = df.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Process the columns on a copy of the data frame. Drop the two columns, merge them and re-establish a single column"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#Well conceived with good human-readable output.  Yet, it's overly complex.  Set one\n",
      "#equal to one or the other and delete the other.\n",
      "\n",
      "def condense(colar):\n",
      "    todrop1, todrop2 = colar[i]\n",
      "    df[todrop1] = df[todrop1] | df[todrop2]\n",
      "    df = df.drop(todrop2)\n",
      "\n",
      "#####\n",
      "#####\n",
      "    \n",
      "pattern = r'[\\',.!\\[\\]\\>]*'\n",
      "colar=compDiffWords(lcCols)\n",
      "theCols = dfA.columns\n",
      "n=len(colar)\n",
      "for i in range(0, n):\n",
      "    print \"dropping \", theCols[colar[i][0]]\n",
      "    print \"dropping \", theCols[colar[i][1]]\n",
      "    theNameA = df.columns[colar[i][0]]\n",
      "    theNameA = theNameA.lower()\n",
      "    theNameA = re.sub(pattern, '', theNameA)\n",
      "    dfA = dfA.drop([theCols[colar[i][0]]], axis = 1)\n",
      "    dfA = dfA.drop([theCols[colar[i][1]]], axis = 1)\n",
      "    theCol = np.array(df[theCols[colar[i][0]]] | df[theCols[colar[i][1]]])\n",
      "    print \"adding union for: \", theNameA\n",
      "    print \"-----------------------------------\"\n",
      "    dfA[theNameA] = np.array(df[theCols[colar[i][0]]] | df[theCols[colar[i][1]]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping  All Along The Watchtower\n",
        "dropping  All Along the Watchtower\n",
        "adding union for:  all along the watchtower\n",
        "-----------------------------------\n",
        "dropping  Big RIver\n",
        "dropping  Big River\n",
        "adding union for:  big river\n",
        "-----------------------------------\n",
        "dropping  Blues For Allah\n",
        "dropping  Blues For Allah Jam\n",
        "adding union for:  blues for allah\n",
        "-----------------------------------\n",
        "dropping  Box Of Rain\n",
        "dropping  Box of Rain\n",
        "adding union for:  box of rain\n",
        "-----------------------------------\n",
        "dropping  Caution\n",
        "dropping  Caution Jam\n",
        "adding union for:  caution\n",
        "-----------------------------------\n",
        "dropping  Comes A Time\n",
        "dropping  Comes a Time\n",
        "adding union for:  comes a time\n",
        "-----------------------------------\n",
        "dropping  Comments: was there a Playin' Reprise???\n",
        "dropping  Comments: was there a Playin' reprise??\n",
        "adding union for:  comments: was there a playin reprise???\n",
        "-----------------------------------\n",
        "dropping  Drums\n",
        "dropping  drums\n",
        "adding union for:  drums\n",
        "-----------------------------------\n",
        "dropping  Fire On the Mountain\n",
        "dropping  Fire on the Mountain\n",
        "adding union for:  fire on the mountain\n",
        "-----------------------------------\n",
        "dropping  Gloria\n",
        "dropping  Gloria Jam\n",
        "adding union for:  gloria\n",
        "-----------------------------------\n",
        "dropping  Goin' Down the Road Feelin' Bad\n",
        "dropping  Goin' Down the Road Feeling Bad\n",
        "adding union for: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " goin down the road feelin bad\n",
        "-----------------------------------\n",
        "dropping  Hell In a Bucket\n",
        "dropping  Hell in a Bucket\n",
        "adding union for:  hell in a bucket\n",
        "-----------------------------------\n",
        "dropping  Here Come Sunshine\n",
        "dropping  Here Comes Sunshine\n",
        "adding union for:  here come sunshine\n",
        "-----------------------------------\n",
        "dropping  Hey Bo Diddiey\n",
        "dropping  Hey Bo Diddley\n",
        "adding union for:  hey bo diddiey\n",
        "-----------------------------------\n",
        "dropping  I'm A Man\n",
        "dropping  I'm a Man\n",
        "adding union for:  im a man\n",
        "-----------------------------------\n",
        "dropping  Jack Stnaw\n",
        "dropping  Jack Straw\n",
        "adding union for:  jack stnaw\n",
        "-----------------------------------\n",
        "dropping  Jam\n",
        "dropping  jam\n",
        "adding union for:  jam\n",
        "-----------------------------------\n",
        "dropping  Let It Grow\n",
        "dropping  Let it Grow\n",
        "adding union for:  let it grow\n",
        "-----------------------------------\n",
        "dropping  Loos Lucy\n",
        "dropping  Loose Lucy\n",
        "adding union for:  loos lucy\n",
        "-----------------------------------\n",
        "dropping  Me & M Uncle\n",
        "dropping  Me & My Uncle\n",
        "adding union for: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " me & m uncle\n",
        "-----------------------------------\n",
        "dropping  Me and My UNcle\n",
        "dropping  Me and My Uncle\n",
        "adding union for:  me and my uncle\n",
        "-----------------------------------\n",
        "dropping  Might As Well\n",
        "dropping  Might as Well\n",
        "adding union for:  might as well\n",
        "-----------------------------------\n",
        "dropping  Mojo\n",
        "dropping  Mojo Jam\n",
        "adding union for:  mojo\n",
        "-----------------------------------\n",
        "dropping  Mr Charlie\n",
        "dropping  Mr. Charlie\n",
        "adding union for:  mr charlie\n",
        "-----------------------------------\n",
        "dropping  Playin' in the Band\n",
        "dropping  Playing in the Band\n",
        "adding union for:  playin in the band\n",
        "-----------------------------------\n",
        "dropping  Qave That Flag\n",
        "dropping  Wave That Flag\n",
        "adding union for:  qave that flag\n",
        "-----------------------------------\n",
        "dropping  Ramble On Rose\n",
        "dropping  Ramble on Rose\n",
        "adding union for:  ramble on rose\n",
        "-----------------------------------\n",
        "dropping  Rockin Pneumonia\n",
        "dropping  Rockin' Pneumonia\n",
        "adding union for:  rockin pneumonia\n",
        "-----------------------------------\n",
        "dropping  SUgaree\n",
        "dropping  Sugaree\n",
        "adding union for: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sugaree\n",
        "-----------------------------------\n",
        "dropping  Saturday Nigh\n",
        "dropping  Saturday Night\n",
        "adding union for:  saturday nigh\n",
        "-----------------------------------\n",
        "dropping  Ship Of Fools\n",
        "dropping  Ship of Fools\n",
        "adding union for:  ship of fools\n",
        "-----------------------------------\n",
        "dropping  Sing Me Back Hom\n",
        "dropping  Sing Me Back Home\n",
        "adding union for:  sing me back hom\n",
        "-----------------------------------\n",
        "dropping  Smokestack Lightnin'\n",
        "dropping  Smokestack Lightning\n",
        "adding union for:  smokestack lightnin\n",
        "-----------------------------------\n",
        "dropping  Space\n",
        "dropping  space\n",
        "adding union for:  space\n",
        "-----------------------------------\n",
        "dropping  Stir It Up\n",
        "dropping  Stir it Up\n",
        "adding union for:  stir it up\n",
        "-----------------------------------\n",
        "dropping  Sugar Magnolia\n",
        "dropping  Sugar Magnolla\n",
        "adding union for:  sugar magnolia\n",
        "-----------------------------------\n",
        "dropping  Supplication\n",
        "dropping  Supplication Jam\n",
        "adding union for:  supplication\n",
        "-----------------------------------\n",
        "dropping  Tennesse Jed\n",
        "dropping  Tennessee Jed\n",
        "adding union for:  tennesse jed\n",
        "-----------------------------------\n",
        "dropping  The Eleven\n",
        "dropping  The Eleven Jam\n",
        "adding union for: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the eleven\n",
        "-----------------------------------\n",
        "dropping  The Race Is On\n",
        "dropping  The Race is On\n",
        "adding union for:  the race is on\n",
        "-----------------------------------\n",
        "dropping  Tomorrow Is Forever\n",
        "dropping  Tomorrow is Forever\n",
        "adding union for:  tomorrow is forever\n",
        "-----------------------------------\n",
        "dropping  Touch Of Grey\n",
        "dropping  Touch of Grey\n",
        "adding union for:  touch of grey\n",
        "-----------------------------------\n",
        "dropping  TrucKin\n",
        "dropping  Truckin'\n",
        "adding union for:  truckin\n",
        "-----------------------------------\n",
        "dropping  Turn On Your Love Light\n",
        "dropping  Turn on Your Love Light\n",
        "adding union for:  turn on your love light\n",
        "-----------------------------------\n",
        "dropping  Uncle John's Band\n",
        "dropping  Uncle John's Band's Jam\n",
        "adding union for:  uncle johns band\n",
        "-----------------------------------\n",
        "dropping  WRS Part 1\n",
        "dropping  WRS Part l\n",
        "adding union for:  wrs part 1\n",
        "-----------------------------------\n",
        "dropping  Whar' Rat\n",
        "dropping  Wharf Rat\n",
        "adding union for:  whar rat\n",
        "-----------------------------------\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For \"Me and My Uncle\" there were 4 columns!!\n",
      "\n",
      "dropping  Me & M Uncle\n",
      "dropping  Me & My Uncle\n",
      "adding union for:  me & my uncle\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "dropping  Me and My UNcle\n",
      "dropping  Me and My Uncle\n",
      "adding union for:  me and my uncle\n",
      "\n",
      "We now 2 columns for this song. \n",
      "\n",
      "Repeating the procedure above will eliminate this final issue."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfB = dfA\n",
      "lcColsB = list(dfA.columns)\n",
      "patternC = r'&'\n",
      "for i in range(0,len(lcColsB)):\n",
      "    lcColsB[i] = re.sub(patternC, 'and', lcColsB[i])\n",
      "pattern = r'[\\',.!\\[\\]\\>]*'\n",
      "colarB=compDiffWords(lcColsB)\n",
      "theColsB = dfB.columns\n",
      "n=len(colarB)\n",
      "for i in range(0, n):\n",
      "    print \"dropping \", theColsB[colarB[i][0]]\n",
      "    print \"dropping \", theColsB[colarB[i][1]]\n",
      "    theNameA = dfA.columns[colarB[i][0]]\n",
      "    theNameA = theNameA.lower()\n",
      "    theNameA = re.sub(pattern, '', theNameA)\n",
      "    theNameA = re.sub(patternC, 'and', theNameA)\n",
      "    print \"the NameA is \" , theNameA\n",
      "    dfB = dfB.drop([theColsB[colarB[i][0]]], axis = 1)\n",
      "    dfB = dfB.drop([theColsB[colarB[i][1]]], axis = 1)\n",
      "    theColB = np.array(dfA[theColsB[colarB[i][0]]] | dfA[theColsB[colarB[i][1]]])\n",
      "    print \"adding union for: \", theNameA\n",
      "    print \"-----------------------------------\"\n",
      "    dfB[theNameA] = np.array(dfA[theColsB[colarB[i][0]]] | dfA[theColsB[colarB[i][1]]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping  me & m uncle\n",
        "dropping  me and my uncle\n",
        "the NameA is  me and m uncle\n",
        "adding union for:  me and m uncle\n",
        "-----------------------------------\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drop the columns that are \"comments\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "patternC = r'Comments'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regex = re.compile(patternC, flags=re.IGNORECASE)\n",
      "theCols = dfB.columns\n",
      "for i in range(0,len(theCols)):\n",
      "    if(len(regex.findall(theCols[i]))>0):\n",
      "        print \"dropping \", theCols[i]\n",
      "        dfB = dfB.drop([theCols[i]], axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping  Comments: Baba Olatungi and Bela Fleck and the Flecktones Opened, Nationwide FM\n",
        "dropping  Comments: Bill Graham Memorial Concert, FM Broadcast\n",
        "dropping  Comments: Bob and Jerry Acoustic\n",
        "dropping  Comments: Brent Mydland's First Show\n",
        "dropping  Comments: Brent Mydland's Last Show.  Brent Died on 7/26, Three Days Later.\n",
        "dropping  Comments: Carlos Santana and his band opened\n",
        "dropping  Comments: Chinese New Year\n",
        "dropping  Comments: David Letterman\n",
        "dropping  Comments: Dwight Yoakam opened\n",
        "dropping  Comments: First Vince \"AWBYGN\"\n",
        "dropping  Comments: First Vince \"Attics\"\n",
        "dropping  Comments: Johnny Clegg and Savuka Opened\n",
        "dropping  Comments: Letterman\n",
        "dropping  Comments: Little Feat opened\n",
        "dropping  Comments: Nuclear Disarmament Benefit\n",
        "dropping  Comments: Rex Foundation Benefit\n",
        "dropping  Comments: Santana Opened\n",
        "dropping  Comments: Sing Out For Sight\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dropping  Comments: Summer Solstice Show\n",
        "dropping  Comments: Teddy Bear Picnic Before Stranger\n",
        "dropping  Comments: Vince Welnik's First Show.\n",
        "dropping  Comments: Vince completes one year with the band\n",
        "dropping  Comments: Violent Femmes opened\n",
        "dropping  Comments: With Branford Marsalis, Hamza El Din\n",
        "dropping  Comments: With Carlos Santana and Gary Duncan\n",
        "dropping  Comments: the Tomorrow Show\n",
        "dropping  comments: was there a playin reprise???\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Drop some other columns for which the song names are unknown"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfB = dfB.drop(['?????'], axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfB = dfB.drop(['[set list unknown]'], axis = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for i in range(1,len(theCols)):\n",
      " #   print i, theCols[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTest = dfB.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for i in range(0, len(dfTest.columns)):\n",
      " #   print i, dfTest.columns[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Re-index the entire dataset using the scrubbed names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#This is unnecessary.  All that matters is that the columns are uniquely named."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#The distinction between Year and zYear isn't clear.\n",
      "patternC = r'&'\n",
      "pattern = r'[\\',.!\\[\\]\\>]*'\n",
      "for i in range(0, len(dfB.columns)):\n",
      "    theNameA = dfB.columns[i]\n",
      "    theNameA = theNameA.lower()\n",
      "    theNameA = re.sub(pattern, '', theNameA)\n",
      "    theNameA = re.sub(patternC, 'and', theNameA)\n",
      "    if theNameA == 'year':\n",
      "        theNameA = 'zYEAR'\n",
      "    dfTest = dfTest.drop([dfB.columns[i]], axis = 1)\n",
      "    dfTest[theNameA] = np.array(dfB[dfB.columns[i]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theCols = list(dfTest.columns)\n",
      "theCols.sort()\n",
      "dfTest = dfTest.reindex(columns=theCols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "dfTest is the master"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dfTestB = dfTest.copy()\n",
      "#dfTestC = dfTest.copy()\n",
      "#dfTestD = dfTest.copy()\n",
      "#dfTestE = dfTest.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 109
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the cleaned up list of final song names."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for i in range(0, len(dfTest.columns)):\n",
      " #   print i, dfTest.columns[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####It's by no means perfect. There are still columns that could be merged. But let's run with this."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I found what appears to be a complete Grateful Dead songlist. \n",
      "\n",
      "Using the external list of songs I wanted to see how many matched the song titles that are the columns headings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = r'[\\',.!\\[\\]\\>]*'\n",
      "patternC = r'&'\n",
      "founda = np.zeros(len(dfTest.columns)-1)\n",
      "for i in range(0,len(kS['Grateful Dead Song List'])):\n",
      "    for j in range(0, len(dfTest.columns)-1):\n",
      "        theSong = re.sub(pattern, '', kS['Grateful Dead Song List'][i])\n",
      "        theSong = re.sub(patternC, 'and', theSong)\n",
      "        theSong = theSong.lower()\n",
      "        #print theSong\n",
      "        if theSong == dfTest.columns[j]:\n",
      "            founda[j] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'kS' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-111-411c587b5f7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpatternC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'&'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfounda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Grateful Dead Song List'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtheSong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Grateful Dead Song List'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'kS' is not defined"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####The 1's in the array below were matches. Ideally one would clean up the rest. Maybe it's just correcting the title for minor spelling mistakes or slight innaccuracies in the song titles themselves."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "founda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "        0.,  0.,  0.,  0.])"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are the songs that did not match up"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#count = 0\n",
      "#for j in range(0, len(dfTest.columns)-1):\n",
      "#    if founda[j] == 0:\n",
      "#        count = count + 1\n",
      "#        print dfTest.columns[j]\n",
      "#print count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Naive Bayes - binary classifier using Multinomial"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (dfTestB[\"zYEAR\"] < 1980).sum()\n",
      "print ((dfTestB[\"zYEAR\"] < 1990) & (dfTestB[\"zYEAR\"] > 1979)).sum()\n",
      "print (dfTestB[\"zYEAR\"] > 1989).sum()\n",
      "print len(dfTestB[\"zYEAR\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'dfTestB' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-115-bfccb77470eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdfTestB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"zYEAR\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1980\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTestB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"zYEAR\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1990\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdfTestB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"zYEAR\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1979\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdfTestB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"zYEAR\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1989\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfTestB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"zYEAR\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'dfTestB' is not defined"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The decade of the 1980s has 722. Need to downsample this class to 410, to balance with the 410 of the pre-80s, post-90s group.\n",
      "\n",
      "Also need to downsample the pre-1980 group to 205."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where(dfTestB['zYEAR'] < 1980)[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = np.random.RandomState(34)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.shuffle(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestB = dfTestB.drop(dfTestB.index[indices[205:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where(dfTestB['zYEAR'] < 1980)[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where((dfTestB['zYEAR'] < 1990) & (dfTestB['zYEAR'] > 1979))[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = np.random.RandomState(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.shuffle(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#When dropping good idea to save as new variable\n",
      "\n",
      "dfTestB = dfTestB.drop(dfTestB.index[indices[410:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where((dfTestB['zYEAR'] < 1990) & (dfTestB['zYEAR'] > 1979))[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (dfTestB[\"zYEAR\"] < 1980).sum()\n",
      "print ((dfTestB[\"zYEAR\"] < 1990) & (dfTestB[\"zYEAR\"] > 1979)).sum()\n",
      "print (dfTestB[\"zYEAR\"] > 1989).sum()\n",
      "print len(dfTestB[\"zYEAR\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestC = dfTestB.copy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dfTestC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dd=(dfTestC[\"zYEAR\"] < 1980)\n",
      "dd1=(dfTestC[\"zYEAR\"] > 1989)\n",
      "dd2=((dfTestC[\"zYEAR\"] > 1979) & (dfTestC[\"zYEAR\"] < 1990))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestC[\"zYEAR\"][dd] = 0\n",
      "dfTestC[\"zYEAR\"][dd1] = 0\n",
      "dfTestC[\"zYEAR\"][dd2] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dfTestC"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy_report(_clf, xtrain,ytrain,xtest, ytest):\n",
      "    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = _clf.score(xtrain, ytrain)\n",
      "    test_accuracy = _clf.score(xtest, ytest)\n",
      "\n",
      "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Note about Stratified Shuffle Split. \n",
      "\n",
      "I have used test size = 0.5 which splits the data into 2 folds, half for training and half for testing.\n",
      "\n",
      "The samples that appear in each fold are chosen randomnly.\n",
      "\n",
      "The folds are made preserving the percentage of samples in each class. \n",
      "\n",
      "By iterating 10 times it runs what is essentially 2 fold cross validation with a new randomnly chosen training and test set each time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#A note on the terminology: a fold is the number of times the sample is redivided"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theCols = dfTestC.columns\n",
      "theCols = theCols[:-1]\n",
      "X = dfTestC.as_matrix(columns = theCols)\n",
      "#print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = (dfTestC[\"zYEAR\"]).values.astype(np.int)\n",
      "sss = StratifiedShuffleSplit(y, 10, test_size=0.5, random_state=32)      \n",
      "models = {}\n",
      "count = 1\n",
      "for train_index, test_index in sss:\n",
      "    indexName = \"model_\" + str(count) \n",
      "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = X[train_index], X[test_index]\n",
      "    y_train, y_test = y[train_index], y[test_index]\n",
      "    clf_mn = MultinomialNB().fit(X_train, y_train)\n",
      "    print \"model_\", count\n",
      "    accuracy_report(clf_mn, X_train, y_train, X_test, y_test)\n",
      "    models[indexName] = clf_mn\n",
      "    count = count + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Results on the entire dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(y, models['model_5'].predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'models' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-112-7b42d3b32249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Actual\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Predicted\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(y_test, models['model_5'].predict(X_test), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As this is a Bayes Classifier we should be able to get sensible probabilities by feeding in individual song names. (Just as we could by feeding in individual tweets). A word is part of a sentence, a song is part of a playlist."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AnalyzeSong(song, _clf):\n",
      "    anArray = np.zeros(len(dfTest.columns)-1)\n",
      "    found = 0;\n",
      "    \n",
      "    #the song has to be a GD song in the first place\n",
      "    #unlike submitting a playlist we are putting a single '1' in an empty array for a single song.\n",
      "    for i in range(1,len(dfTest.columns)-1):\n",
      "        if song == dfTest.columns[i]:\n",
      "            found = 1\n",
      "            anArray[i] = 1\n",
      "    if found == 1:\n",
      "        print \"\\\"\"  + song + \"\\\" is judged by clasifier to be...\"\n",
      "        if (_clf.predict(anArray) == 0):\n",
      "            print \"Song not from the 1980s playlists\"\n",
      "        else:\n",
      "            print \"Song is from the 1980s playlist\"\n",
      "    else:\n",
      "        print \"Sorry this song is not recognized\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_pick = models['model_5']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSong(\"wicked messenger\", model_pick)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSong(\"althea\", model_pick)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSong(\"all along the watchtower\", model_pick)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSong(\"sugaree\", model_pick)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSong(\"space\", model_pick)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probas_ = model_pick.predict_proba(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Check out the ROC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "false_pos_rate, true_pos_rate, thresholds = roc_curve(y_test, probas_[:, 1])\n",
      "roc_auc = auc(false_pos_rate, true_pos_rate)\n",
      "print \"Area under the ROC curve : %f\" % roc_auc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot ROC curve\n",
      "# setup figure\n",
      "plt.figure(figsize=(10, 8))\n",
      "plt.clf()\n",
      "plt.plot(false_pos_rate, true_pos_rate, label='ROC curve (area = %0.2f)' % roc_auc)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.0])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver Operating Characteristic for Multinomial Naive Bayes')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###MULTI-CLASS LOGISTIC REGRESSION###"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have 3 decades - 1970s, 1980s, 1990s\n",
      "Relabel the Years encoding 0 for 1970s, 1 for 1980s, and 2 for 1990s"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print (dfTestD[\"zYEAR\"] < 1980).sum()\n",
      "print ((dfTestD[\"zYEAR\"] < 1990) & (dfTestD[\"zYEAR\"] > 1979)).sum()\n",
      "print (dfTestD[\"zYEAR\"] > 1989).sum()\n",
      "print len(dfTestD[\"zYEAR\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#zYear is a terribly named variable!  I know I made this comment \n",
      "#up there, but I have to reiterate it."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where(dfTestD['zYEAR'] < 1980)[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = np.random.RandomState(34)\n",
      "r.shuffle(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestD = dfTestD.drop(dfTestD.index[indices[205:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where(dfTestD['zYEAR'] < 1980)[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where((dfTestD['zYEAR'] < 1990) & (dfTestD['zYEAR'] > 1979))[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = np.random.RandomState(65)\n",
      "r.shuffle(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestD = dfTestD.drop(dfTestD.index[indices[205:]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = np.where((dfTestD['zYEAR'] < 1990) & (dfTestD['zYEAR'] > 1979))[0]\n",
      "print len(indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reduce each class to having 205 samples. \n",
      "\n",
      "Downsample the 1970s from 462 to 205, and the 1980s from 722 to 205"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Years = np.array(dfTestD[\"zYEAR\"])\n",
      "Ylr = np.zeros((len(dfTestD[\"zYEAR\"]), 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0, len(dfTestD[\"zYEAR\"])):\n",
      "    if Years[i] < 1980:\n",
      "        Ylr[i] = 0\n",
      "    else:\n",
      "        if Years[i] < 1990:\n",
      "            Ylr[i] = 1\n",
      "        else:\n",
      "            Ylr[i] = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Ylr.shape\n",
      "hh = Ylr.reshape(-1)\n",
      "print hh.shape\n",
      "#for i in range(0, len(Ylr)):\n",
      "    #print i, Ylr[i], Years[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theCols = dfTestD.columns\n",
      "theCols = theCols[:-1]\n",
      "X = dfTestD.as_matrix(columns = theCols)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg=10000\n",
      "y = Ylr.reshape(-1)\n",
      "sss = StratifiedShuffleSplit(y, 10, test_size=0.5, random_state=32)     \n",
      "models = {}\n",
      "count = 1\n",
      "for train_index, test_index in sss:\n",
      "    indexName = \"LRmodel_\" + str(count) \n",
      "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = X[train_index], X[test_index]\n",
      "    y_train, y_test = y[train_index], y[test_index]    \n",
      "    clf_lr = LogisticRegression(C=reg).fit(X_train, y_train)\n",
      "    print \"LR-model_\", count\n",
      "    accuracy_report(clf_lr, X_train, y_train, X_test, y_test)\n",
      "    models[indexName] = clf_lr\n",
      "    count = count + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_pick = models['LRmodel_9']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(Ylr.reshape(-1), model_pick.predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(y_test, model_pick.predict(X_test), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Although this works well as a 3 class classifier, it cannot be used to classify individual songs (as was done for the Bayes classifier). To work as a classifier requires an entire playlist as input."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#The multilabel model is sophisticated.  Well done staying organized\n",
      "#throughout the analysis.  A single song could be submitted as a single\n",
      "#song concert."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Multi-class Naive Bayes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AnalyzeSongLR(song, _clf):\n",
      "    anArray = np.zeros(len(dfTestD.columns)-1)\n",
      "    found = 0;\n",
      "    \n",
      "    for i in range(0,len(dfTestD.columns)-1):\n",
      "        if song == dfTestD.columns[i]:\n",
      "            found = 1\n",
      "            anArray[i] = 1\n",
      "            \n",
      "    if found == 1:\n",
      "        print _clf.predict(anArray)\n",
      "        print _clf.predict_proba(anArray)\n",
      "        print \"\\\"\"  + song + \"\\\" is judged by clasifier to be...\"\n",
      "        if (_clf.predict(anArray) == 0):\n",
      "            print \"Song is from the 1970s playlist\"\n",
      "        else:\n",
      "            if (_clf.predict(anArray) == 1):\n",
      "                print \"Song is from the 1980s playlist\"\n",
      "            else:\n",
      "                if(_clf.predict(anArray) == 2):\n",
      "                    print \"Song is from the 1990s playlist\"\n",
      "        \n",
      "    else:\n",
      "        print \"Sorry this song is not recognized\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sss = StratifiedShuffleSplit(y, 10, test_size=0.5, random_state=5)     \n",
      "models = {}\n",
      "count = 1\n",
      "for train_index, test_index in sss:\n",
      "    indexName = \"MN_MC_model_\" + str(count) \n",
      "    X_train, X_test = X[train_index], X[test_index]\n",
      "    y_train, y_test = y[train_index], y[test_index]\n",
      "    clf_mn_mc = MultinomialNB().fit(X_train, y_train)\n",
      "    print \"MN_MC_model_\", count\n",
      "    accuracy_report(clf_mn_mc, X_train, y_train, X_test, y_test)\n",
      "    models[indexName] = clf_mn_mc\n",
      "    count = count + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_pick_MN_MC = models['MN_MC_model_2']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(Ymc.reshape(-1), model_pick_MN_MC.predict(X), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.crosstab(y_test, model_pick_MN_MC.predict(X_test), rownames=[\"Actual\"], colnames=[\"Predicted\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"wicked messenger\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"aint superstitious\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"dark star\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"space\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"althea\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"valley road\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"all along the watchtower\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"sugaree\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"drums\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"so many roads\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"box of rain\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"friend of the devil\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"uncle johns band\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"brokedown palace\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"cumberland blues\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"dire wolf\",model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AnalyzeSongLR(\"sugar magnolia\", model_pick_MN_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Predicting for a single year - 1987"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1972,1993):\n",
      "    print i , (dfTest[\"zYEAR\"] == i).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data volume would be an issue with cross validation. 1975 is a problematic year with only 4 data points. It may also have been that the 4 shows they did in 1987 were all the same, which again, potentially, reduces the number of data points providing information to less than 4. \n",
      "\n",
      "To balance the dataset around 1975 would potentially mean loosing a lot of data. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Data Visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestE.sum(axis=0)[:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dff = dfTestE.sum(axis=0)[:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inds = dff.values > 200"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(dff[inds])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dffDF = pd.DataFrame(dff[inds])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dffDF.plot(kind=\"bar\", figsize=(15,5), ylim=(100, 1200), title=\"Most Played Songs (Starting frequency 100 times)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Year = dfTestE[\"zYEAR\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = dfTestE.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dffDF = dfTestE[cols[:-1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(15, 5))\n",
      "plt.scatter(Year, dffDF.sum(axis = 1), color='blue', label=\"Training Temperature Responses\") \n",
      "plt.title(\"Playlists per Year (number of blue dots) & Songs per playlist\")\n",
      "plt.ylabel(\"Number of Songs in Playlist\")\n",
      "plt.xlabel(\"Year\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some playlists apparently contained no songs! Just shows the data could still do with some more cleaning!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def year_grouping(year):\n",
      "    if year < 1980:\n",
      "        return \"70s\"\n",
      "    elif year >= 1980 and year < 1990:\n",
      "        return \"80s\"\n",
      "    elif year >=1990:\n",
      "        return \"90s\"\n",
      "    else:\n",
      "        return np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestE['year_group'] = dfTestE.zYEAR.apply(lambda x: year_grouping(x))\n",
      "dfTestE[['zYEAR', 'year_group']].head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfTestE.groupby('year_group').sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#JP\n",
      "#I had trouble running the code because dftestb was missing.\n",
      "#The code could be more articulate.  The result\n",
      "#would be (1) code that could be reused.  The functions\n",
      "#you built here are abstract and robust and may come in handy\n",
      "#down the road.  And (2) results that build on each other and\n",
      "#are more easily justified.  A real pleasure to get lost in\n",
      "#the weeds with you on a \"long strange trip\" through\n",
      "#parsed Grateful Dead data."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}