{
 "metadata": {
  "name": "",
  "signature": "sha256:e88b29771664845a9de057363546661bf78b6486c1c4ede0652a65151815b26d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [\"Human machine interface for lab abc computer applications\",\n",
      "              \"A survey of user opinion of computer system response time\",\n",
      "              \"The EPS user interface management system\",\n",
      "              \"System and human system engineering testing of EPS\",\n",
      "              \"Relation of user perceived response time to error measurement\",\n",
      "              \"The generation of random binary unordered trees\",\n",
      "              \"The intersection graph of paths in trees\",\n",
      "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
      "              \"Graph minors A survey\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Remove common words and tokenize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stoplist = set('for a of the and to in'.split())\n",
      "print stoplist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['a', 'and', 'for', 'of', 'to', 'in', 'the'])\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
      "\n",
      "for t in texts:\n",
      "    print t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications']\n",
        "['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time']\n",
        "['eps', 'user', 'interface', 'management', 'system']\n",
        "['system', 'human', 'system', 'engineering', 'testing', 'eps']\n",
        "['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement']\n",
        "['generation', 'random', 'binary', 'unordered', 'trees']\n",
        "['intersection', 'graph', 'paths', 'trees']\n",
        "['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering']\n",
        "['graph', 'minors', 'survey']\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Remove words that appear only once"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_tokens = []\n",
      "for list in texts:\n",
      "    all_tokens = all_tokens + list\n",
      "\n",
      "print all_tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications', 'survey', 'user', 'opinion', 'computer', 'system', 'response', 'time', 'eps', 'user', 'interface', 'management', 'system', 'system', 'human', 'system', 'engineering', 'testing', 'eps', 'relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement', 'generation', 'random', 'binary', 'unordered', 'trees', 'intersection', 'graph', 'paths', 'trees', 'graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering', 'graph', 'minors', 'survey']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "print tokens_once"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['generation', 'random', 'iv', 'engineering', 'relation', 'measurement', 'unordered', 'binary', 'abc', 'ordering', 'machine', 'quasi', 'testing', 'paths', 'lab', 'applications', 'management', 'intersection', 'perceived', 'widths', 'well', 'error', 'opinion'])\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texts = [[word for word in text if word not in tokens_once]\n",
      "          for text in texts]\n",
      "for t in texts:\n",
      "    print t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['human', 'interface', 'computer']\n",
        "['survey', 'user', 'computer', 'system', 'response', 'time']\n",
        "['eps', 'user', 'interface', 'system']\n",
        "['system', 'human', 'system', 'eps']\n",
        "['user', 'response', 'time']\n",
        "['trees']\n",
        "['graph', 'trees']\n",
        "['graph', 'minors', 'trees']\n",
        "['graph', 'minors', 'survey']\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(texts)\n",
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(dictionary.token2id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'minors': 11, u'graph': 10, u'system': 5, u'trees': 9, u'eps': 8, u'computer': 0, u'survey': 4, u'user': 7, u'human': 1, u'time': 6, u'interface': 2, u'response': 3}\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "\n",
      "for c in corpus:\n",
      "    print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 1), (1, 1), (2, 1)]\n",
        "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
        "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
        "[(1, 1), (5, 2), (8, 1)]\n",
        "[(3, 1), (6, 1), (7, 1)]\n",
        "[(9, 1)]\n",
        "[(9, 1), (10, 1)]\n",
        "[(9, 1), (10, 1), (11, 1)]\n",
        "[(4, 1), (10, 1), (11, 1)]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda_model = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for topic in lda_model.print_topics():\n",
      "    print topic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.165*system + 0.115*user + 0.114*survey + 0.113*response + 0.113*time + 0.068*graph + 0.067*human + 0.067*computer + 0.066*minors + 0.066*eps\n",
        "0.179*trees + 0.106*system + 0.102*eps + 0.099*interface + 0.098*user + 0.067*graph + 0.060*minors + 0.060*human + 0.059*response + 0.058*time\n",
        "0.157*trees + 0.152*graph + 0.135*interface + 0.089*computer + 0.089*minors + 0.087*human + 0.074*user + 0.071*system + 0.070*eps + 0.026*time\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### When num_topics = 3:\n",
      "\n",
      "- topic1 = \"system/user\"\n",
      "\n",
      "- topic2 = \"trees/system\"\n",
      "\n",
      "- topic3 = \"trees/graph\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Todo: given a new sentence, which topic does it map closest to?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}