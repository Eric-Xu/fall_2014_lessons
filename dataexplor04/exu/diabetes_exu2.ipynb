{
 "metadata": {
  "name": "",
  "signature": "sha256:e62fc199df26e9c2315050fc411d53d697420c4fa77afa64320d8c282cb24a0c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_diabetes\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.linear_model import Lasso\n",
      "from sklearn.feature_selection import SelectKBest\n",
      "from sklearn.feature_selection import f_regression\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.preprocessing import PolynomialFeatures\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The diabetes dataset consists of 10 physiological variables (age, sex, weight, blood pressure) measure on 442\n",
      "patients, and an indication of disease progression after one year:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = load_diabetes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df=pd.DataFrame(data.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['y']=data.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>y</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 4.420000e+02</td>\n",
        "      <td> 442.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>-3.634285e-16</td>\n",
        "      <td> 1.308343e-16</td>\n",
        "      <td>-8.045349e-16</td>\n",
        "      <td> 1.281655e-16</td>\n",
        "      <td>-8.835316e-17</td>\n",
        "      <td> 1.327024e-16</td>\n",
        "      <td>-4.574646e-16</td>\n",
        "      <td> 3.777301e-16</td>\n",
        "      <td>-3.830854e-16</td>\n",
        "      <td>-3.412882e-16</td>\n",
        "      <td> 152.133484</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td> 4.761905e-02</td>\n",
        "      <td>  77.093005</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>-1.072256e-01</td>\n",
        "      <td>-4.464164e-02</td>\n",
        "      <td>-9.027530e-02</td>\n",
        "      <td>-1.123996e-01</td>\n",
        "      <td>-1.267807e-01</td>\n",
        "      <td>-1.156131e-01</td>\n",
        "      <td>-1.023071e-01</td>\n",
        "      <td>-7.639450e-02</td>\n",
        "      <td>-1.260974e-01</td>\n",
        "      <td>-1.377672e-01</td>\n",
        "      <td>  25.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>-3.729927e-02</td>\n",
        "      <td>-4.464164e-02</td>\n",
        "      <td>-3.422907e-02</td>\n",
        "      <td>-3.665645e-02</td>\n",
        "      <td>-3.424784e-02</td>\n",
        "      <td>-3.035840e-02</td>\n",
        "      <td>-3.511716e-02</td>\n",
        "      <td>-3.949338e-02</td>\n",
        "      <td>-3.324879e-02</td>\n",
        "      <td>-3.317903e-02</td>\n",
        "      <td>  87.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 5.383060e-03</td>\n",
        "      <td>-4.464164e-02</td>\n",
        "      <td>-7.283766e-03</td>\n",
        "      <td>-5.670611e-03</td>\n",
        "      <td>-4.320866e-03</td>\n",
        "      <td>-3.819065e-03</td>\n",
        "      <td>-6.584468e-03</td>\n",
        "      <td>-2.592262e-03</td>\n",
        "      <td>-1.947634e-03</td>\n",
        "      <td>-1.077698e-03</td>\n",
        "      <td> 140.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 3.807591e-02</td>\n",
        "      <td> 5.068012e-02</td>\n",
        "      <td> 3.124802e-02</td>\n",
        "      <td> 3.564384e-02</td>\n",
        "      <td> 2.835801e-02</td>\n",
        "      <td> 2.984439e-02</td>\n",
        "      <td> 2.931150e-02</td>\n",
        "      <td> 3.430886e-02</td>\n",
        "      <td> 3.243323e-02</td>\n",
        "      <td> 2.791705e-02</td>\n",
        "      <td> 211.500000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 1.107267e-01</td>\n",
        "      <td> 5.068012e-02</td>\n",
        "      <td> 1.705552e-01</td>\n",
        "      <td> 1.320442e-01</td>\n",
        "      <td> 1.539137e-01</td>\n",
        "      <td> 1.987880e-01</td>\n",
        "      <td> 1.811791e-01</td>\n",
        "      <td> 1.852344e-01</td>\n",
        "      <td> 1.335990e-01</td>\n",
        "      <td> 1.356118e-01</td>\n",
        "      <td> 346.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "                  0             1             2             3             4  \\\n",
        "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
        "mean  -3.634285e-16  1.308343e-16 -8.045349e-16  1.281655e-16 -8.835316e-17   \n",
        "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
        "min   -1.072256e-01 -4.464164e-02 -9.027530e-02 -1.123996e-01 -1.267807e-01   \n",
        "25%   -3.729927e-02 -4.464164e-02 -3.422907e-02 -3.665645e-02 -3.424784e-02   \n",
        "50%    5.383060e-03 -4.464164e-02 -7.283766e-03 -5.670611e-03 -4.320866e-03   \n",
        "75%    3.807591e-02  5.068012e-02  3.124802e-02  3.564384e-02  2.835801e-02   \n",
        "max    1.107267e-01  5.068012e-02  1.705552e-01  1.320442e-01  1.539137e-01   \n",
        "\n",
        "                  5             6             7             8             9  \\\n",
        "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
        "mean   1.327024e-16 -4.574646e-16  3.777301e-16 -3.830854e-16 -3.412882e-16   \n",
        "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
        "min   -1.156131e-01 -1.023071e-01 -7.639450e-02 -1.260974e-01 -1.377672e-01   \n",
        "25%   -3.035840e-02 -3.511716e-02 -3.949338e-02 -3.324879e-02 -3.317903e-02   \n",
        "50%   -3.819065e-03 -6.584468e-03 -2.592262e-03 -1.947634e-03 -1.077698e-03   \n",
        "75%    2.984439e-02  2.931150e-02  3.430886e-02  3.243323e-02  2.791705e-02   \n",
        "max    1.987880e-01  1.811791e-01  1.852344e-01  1.335990e-01  1.356118e-01   \n",
        "\n",
        "                y  \n",
        "count  442.000000  \n",
        "mean   152.133484  \n",
        "std     77.093005  \n",
        "min     25.000000  \n",
        "25%     87.000000  \n",
        "50%    140.500000  \n",
        "75%    211.500000  \n",
        "max    346.000000  "
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>y</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.038076</td>\n",
        "      <td> 0.050680</td>\n",
        "      <td> 0.061696</td>\n",
        "      <td> 0.021872</td>\n",
        "      <td>-0.044223</td>\n",
        "      <td>-0.034821</td>\n",
        "      <td>-0.043401</td>\n",
        "      <td>-0.002592</td>\n",
        "      <td> 0.019908</td>\n",
        "      <td>-0.017646</td>\n",
        "      <td> 151</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>-0.001882</td>\n",
        "      <td>-0.044642</td>\n",
        "      <td>-0.051474</td>\n",
        "      <td>-0.026328</td>\n",
        "      <td>-0.008449</td>\n",
        "      <td>-0.019163</td>\n",
        "      <td> 0.074412</td>\n",
        "      <td>-0.039493</td>\n",
        "      <td>-0.068330</td>\n",
        "      <td>-0.092204</td>\n",
        "      <td>  75</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.085299</td>\n",
        "      <td> 0.050680</td>\n",
        "      <td> 0.044451</td>\n",
        "      <td>-0.005671</td>\n",
        "      <td>-0.045599</td>\n",
        "      <td>-0.034194</td>\n",
        "      <td>-0.032356</td>\n",
        "      <td>-0.002592</td>\n",
        "      <td> 0.002864</td>\n",
        "      <td>-0.025930</td>\n",
        "      <td> 141</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>-0.089063</td>\n",
        "      <td>-0.044642</td>\n",
        "      <td>-0.011595</td>\n",
        "      <td>-0.036656</td>\n",
        "      <td> 0.012191</td>\n",
        "      <td> 0.024991</td>\n",
        "      <td>-0.036038</td>\n",
        "      <td> 0.034309</td>\n",
        "      <td> 0.022692</td>\n",
        "      <td>-0.009362</td>\n",
        "      <td> 206</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.005383</td>\n",
        "      <td>-0.044642</td>\n",
        "      <td>-0.036385</td>\n",
        "      <td> 0.021872</td>\n",
        "      <td> 0.003935</td>\n",
        "      <td> 0.015596</td>\n",
        "      <td> 0.008142</td>\n",
        "      <td>-0.002592</td>\n",
        "      <td>-0.031991</td>\n",
        "      <td>-0.046641</td>\n",
        "      <td> 135</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "          0         1         2         3         4         5         6  \\\n",
        "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
        "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
        "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
        "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
        "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
        "\n",
        "          7         8         9    y  \n",
        "0 -0.002592  0.019908 -0.017646  151  \n",
        "1 -0.039493 -0.068330 -0.092204   75  \n",
        "2 -0.002592  0.002864 -0.025930  141  \n",
        "3  0.034309  0.022692 -0.009362  206  \n",
        "4 -0.002592 -0.031991 -0.046641  135  "
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Examine the Correlation Between Predictors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictors = [col for col in df.columns if col != 'y']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[predictors].corr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.173737</td>\n",
        "      <td> 0.185085</td>\n",
        "      <td> 0.335427</td>\n",
        "      <td> 0.260061</td>\n",
        "      <td> 0.219243</td>\n",
        "      <td>-0.075181</td>\n",
        "      <td> 0.203841</td>\n",
        "      <td> 0.270777</td>\n",
        "      <td> 0.301731</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.173737</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.088161</td>\n",
        "      <td> 0.241013</td>\n",
        "      <td> 0.035277</td>\n",
        "      <td> 0.142637</td>\n",
        "      <td>-0.379090</td>\n",
        "      <td> 0.332115</td>\n",
        "      <td> 0.149918</td>\n",
        "      <td> 0.208133</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.185085</td>\n",
        "      <td> 0.088161</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.395415</td>\n",
        "      <td> 0.249777</td>\n",
        "      <td> 0.261170</td>\n",
        "      <td>-0.366811</td>\n",
        "      <td> 0.413807</td>\n",
        "      <td> 0.446159</td>\n",
        "      <td> 0.388680</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.335427</td>\n",
        "      <td> 0.241013</td>\n",
        "      <td> 0.395415</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.242470</td>\n",
        "      <td> 0.185558</td>\n",
        "      <td>-0.178761</td>\n",
        "      <td> 0.257653</td>\n",
        "      <td> 0.393478</td>\n",
        "      <td> 0.390429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.260061</td>\n",
        "      <td> 0.035277</td>\n",
        "      <td> 0.249777</td>\n",
        "      <td> 0.242470</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.896663</td>\n",
        "      <td> 0.051519</td>\n",
        "      <td> 0.542207</td>\n",
        "      <td> 0.515501</td>\n",
        "      <td> 0.325717</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td> 0.219243</td>\n",
        "      <td> 0.142637</td>\n",
        "      <td> 0.261170</td>\n",
        "      <td> 0.185558</td>\n",
        "      <td> 0.896663</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td>-0.196455</td>\n",
        "      <td> 0.659817</td>\n",
        "      <td> 0.318353</td>\n",
        "      <td> 0.290600</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>-0.075181</td>\n",
        "      <td>-0.379090</td>\n",
        "      <td>-0.366811</td>\n",
        "      <td>-0.178761</td>\n",
        "      <td> 0.051519</td>\n",
        "      <td>-0.196455</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td>-0.738493</td>\n",
        "      <td>-0.398577</td>\n",
        "      <td>-0.273697</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 0.203841</td>\n",
        "      <td> 0.332115</td>\n",
        "      <td> 0.413807</td>\n",
        "      <td> 0.257653</td>\n",
        "      <td> 0.542207</td>\n",
        "      <td> 0.659817</td>\n",
        "      <td>-0.738493</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.617857</td>\n",
        "      <td> 0.417212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 0.270777</td>\n",
        "      <td> 0.149918</td>\n",
        "      <td> 0.446159</td>\n",
        "      <td> 0.393478</td>\n",
        "      <td> 0.515501</td>\n",
        "      <td> 0.318353</td>\n",
        "      <td>-0.398577</td>\n",
        "      <td> 0.617857</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0.464670</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td> 0.301731</td>\n",
        "      <td> 0.208133</td>\n",
        "      <td> 0.388680</td>\n",
        "      <td> 0.390429</td>\n",
        "      <td> 0.325717</td>\n",
        "      <td> 0.290600</td>\n",
        "      <td>-0.273697</td>\n",
        "      <td> 0.417212</td>\n",
        "      <td> 0.464670</td>\n",
        "      <td> 1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "          0         1         2         3         4         5         6  \\\n",
        "0  1.000000  0.173737  0.185085  0.335427  0.260061  0.219243 -0.075181   \n",
        "1  0.173737  1.000000  0.088161  0.241013  0.035277  0.142637 -0.379090   \n",
        "2  0.185085  0.088161  1.000000  0.395415  0.249777  0.261170 -0.366811   \n",
        "3  0.335427  0.241013  0.395415  1.000000  0.242470  0.185558 -0.178761   \n",
        "4  0.260061  0.035277  0.249777  0.242470  1.000000  0.896663  0.051519   \n",
        "5  0.219243  0.142637  0.261170  0.185558  0.896663  1.000000 -0.196455   \n",
        "6 -0.075181 -0.379090 -0.366811 -0.178761  0.051519 -0.196455  1.000000   \n",
        "7  0.203841  0.332115  0.413807  0.257653  0.542207  0.659817 -0.738493   \n",
        "8  0.270777  0.149918  0.446159  0.393478  0.515501  0.318353 -0.398577   \n",
        "9  0.301731  0.208133  0.388680  0.390429  0.325717  0.290600 -0.273697   \n",
        "\n",
        "          7         8         9  \n",
        "0  0.203841  0.270777  0.301731  \n",
        "1  0.332115  0.149918  0.208133  \n",
        "2  0.413807  0.446159  0.388680  \n",
        "3  0.257653  0.393478  0.390429  \n",
        "4  0.542207  0.515501  0.325717  \n",
        "5  0.659817  0.318353  0.290600  \n",
        "6 -0.738493 -0.398577 -0.273697  \n",
        "7  1.000000  0.617857  0.417212  \n",
        "8  0.617857  1.000000  0.464670  \n",
        "9  0.417212  0.464670  1.000000  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like there are pretty high correlations between 4 and 5, 5 and 7, 6 and 7."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df[predictors].values\n",
      "y = df.y.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Construct a baseline regressor with all features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reg = LinearRegression()\n",
      "reg.fit(X, y)\n",
      "ypred = reg.predict(X)\n",
      "rmse = np.sqrt(mean_squared_error(ypred, y))\n",
      "print(\"RMSE: %0.2f\" % (rmse.mean()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RMSE: 53.48\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Use SelectKBest to find the best subset regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mses = []\n",
      "nfeatures = range(1, len(predictors))\n",
      "\n",
      "for nfeature in nfeatures:\n",
      "    # compute MSE for different values of k (top features)\n",
      "    selector = SelectKBest(f_regression, k=nfeature)\n",
      "    selector.fit(X, y)\n",
      "    selected = selector.get_support()\n",
      "    feats = [col for (col,sel) in zip(predictors, selected) if sel]\n",
      "    reg = LinearRegression()\n",
      "    X_r = df[feats]\n",
      "    reg.fit(X_r, y)\n",
      "    ypred = reg.predict(X_r)\n",
      "    mses.append(np.sqrt(mean_squared_error(ypred, y)))\n",
      "\n",
      "plt.plot(nfeatures, mses)\n",
      "plt.xlabel(\"number of features\")\n",
      "plt.ylabel(\"RMSE\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<matplotlib.text.Text at 0x1081dd1d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEPCAYAAABFpK+YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108167fd0>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Model selection by cross validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The RMSE falls as the number of features increase - this is expected because we are computing the RMSE off the training set (overfitting). We will now use 10-fold cross validation on each model to calculate a cross-validation MSE which will give us a better idea of the best feature size to use for the problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_errors = []\n",
      "kfold = KFold(len(df), n_folds=10)\n",
      "nfeatures = range(1, len(predictors))\n",
      "\n",
      "for nfeature in nfeatures:\n",
      "    # build model with varying number of features\n",
      "    selector = SelectKBest(f_regression, k=nfeature)\n",
      "    selector.fit(X, y)\n",
      "    selected = selector.get_support()\n",
      "    feats = [col for (col,sel) in zip(predictors, selected) if sel]\n",
      "    X_r = df[feats].values\n",
      "    y = df[\"y\"].values\n",
      "    rmses = []\n",
      "    for train, test in kfold:\n",
      "        # each model is cross validated 10 times\n",
      "        Xtrain, ytrain, Xtest, ytest = X_r[train], y[train], X_r[test], y[test]   \n",
      "        reg = LinearRegression()\n",
      "        reg.fit(Xtrain, ytrain)\n",
      "        ypred = reg.predict(Xtest)\n",
      "        rmses.append(np.sqrt(mean_squared_error(ypred, ytest)))\n",
      "    cv_errors.append(np.mean(rmses))\n",
      "    \n",
      "plt.plot(nfeatures, cv_errors)\n",
      "plt.xlabel(\"number of features\")\n",
      "plt.ylabel(\"RMSE\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<matplotlib.text.Text at 0x108156890>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEPCAYAAABFpK+YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiItMb/B+e079z/43hrAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10818ccd0>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5 seems to be the optimal number of features to use. \n",
      "\n",
      "Next up: lets see if we can lower the MSE even further by using Ridge and Lasso regression to shrink the coefficient estimates."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Compare baseline model with Ridge and Lasso"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_validate(X, y, nfolds, reg_name=None):\n",
      "    if reg_name == \"ridge\":\n",
      "        reg = Ridge()\n",
      "    elif reg_name == \"lasso\":\n",
      "        reg = Lasso()\n",
      "    elif reg_name == \"baseline\":\n",
      "        reg = LinearRegression()\n",
      "    else:\n",
      "        print \"model not defined\"\n",
      "\n",
      "    rmses = []\n",
      "    kfold = KFold(X.shape[0], n_folds=nfolds)\n",
      "    for train, test in kfold:\n",
      "        Xtrain, ytrain, Xtest, ytest = X[train], y[train], X[test], y[test]\n",
      "        reg.fit(Xtrain, ytrain)\n",
      "        ypred = reg.predict(Xtest)\n",
      "        rmses.append(np.sqrt(mean_squared_error(ytest, ypred)))\n",
      "    return np.mean(rmses)\n",
      "\n",
      "X = df[predictors].values\n",
      "y = df[\"y\"].values\n",
      "\n",
      "rmse_baseline = cross_validate(X, y, 10, \"baseline\")\n",
      "rmse_ridge = cross_validate(X, y, 10, \"ridge\")\n",
      "rmse_lasso = cross_validate(X, y, 10, \"lassoa\")\n",
      "\n",
      "print(\"baseline wins with: %0.2f; ridge: %0.2f; lasso: %0.2f\") % (rmse_baseline, rmse_ridge, rmse_lasso)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "model not defined\n"
       ]
      },
      {
       "ename": "UnboundLocalError",
       "evalue": "local variable 'reg' referenced before assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-edb8705c6c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mrmse_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mrmse_ridge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ridge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrmse_lasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lassoa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"baseline wins with: %0.2f; ridge: %0.2f; lasso: %0.2f\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrmse_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_ridge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_lasso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-20-edb8705c6c60>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(X, y, nfolds, reg_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mrmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'reg' referenced before assignment"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fine tune the baseline model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# scores = []\n",
      "\n",
      "# for train, test in KFold(len(df), n_folds=5):\n",
      "#     Xtrain, ytrain, Xtest, ytest = X[train], y[train], X[test], y[test]\n",
      "    \n",
      "#     b = SelectKBest(f_regression, k=5)\n",
      "#     b.fit(Xtrain, ytrain)\n",
      "#     Xtrain = Xtrain[:, b.get_support()]\n",
      "#     Xtest = Xtest[:, b.get_support()]\n",
      "    \n",
      "#     clf = LinearRegression()\n",
      "#     clf.fit(Xtrain, ytrain)    \n",
      "#     scores.append(clf.score(Xtest, ytest))\n",
      "\n",
      "#     yp = clf.predict(Xtest)\n",
      "#     plt.plot(yp, ytest, 'o')\n",
      "#     plt.plot(ytest, ytest, 'r-')\n",
      "    \n",
      "# plt.xlabel(\"Predicted\")\n",
      "# plt.ylabel(\"Observed\")\n",
      "\n",
      "# print(\"CV Score is \", np.mean(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As of now, cross validation has revealed that using the baseline model with 5 features results in the lowest RMSE. Now let's investigate when using 5 features, is there an optimal number of polynomial degrees to fit our model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "degrees = np.arange(6)\n",
      "train_err = np.zeros(len(degrees))\n",
      "validation_err = np.zeros(len(degrees))\n",
      "\n",
      "scores = []\n",
      "\n",
      "for i, degree in enumerate(degrees):\n",
      "    for train, test in KFold(len(df), n_folds=3):\n",
      "        Xtrain, ytrain, Xtest, ytest = X[train], y[train], X[test], y[test]\n",
      "\n",
      "        b = SelectKBest(f_regression, k=5)\n",
      "        b.fit(Xtrain, ytrain)\n",
      "        Xtrain = Xtrain[:, b.get_support()]\n",
      "        Xtest = Xtest[:, b.get_support()]\n",
      "\n",
      "        print b.get_support() # returns the set of selected predictors\n",
      "        \n",
      "        est = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
      "        est.fit(Xtrain, ytrain)\n",
      "        \n",
      "        train_err[i] = np.sqrt(np.mean((ytrain - est.predict(Xtrain)) ** 2))\n",
      "        validation_err[i] = np.sqrt(np.mean((ytest - est.predict(Xtest)) ** 2))\n",
      "        # same as: np.sqrt(mean_squared_error(ytest, est.predict(Xtest)))\n",
      "                        \n",
      "fig, ax = plt.subplots()\n",
      "\n",
      "ax.plot(degrees, validation_err, lw=2, label = 'cross-validation error')\n",
      "ax.plot(degrees, train_err, lw=2, label = 'training error')\n",
      "\n",
      "ax.legend(loc=0)\n",
      "ax.set_xlabel('degree of fit')\n",
      "ax.set_ylabel('RMSE')\n",
      "plt.ylim(-10, 150)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False False  True  True  True]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False False  True  True  True]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False False  True  True  True]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False False  True  True  True]\n",
        "[False False  True  True False False  True  True  True False]\n",
        "[False False  True  True False False  True  True  True False]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[False False  True  True False False False  True  True  True]\n",
        "[False False  True  True False False  True  True  True False]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[False False  True  True False False  True  True  True False]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[False False  True  True False False False  True  True  True]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(-10, 150)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x108352a90>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print validation_err"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[   75.70460231    54.52716532    55.1963555     70.85459868   136.84923024\n",
        "  2226.51041215]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Conclusion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the cross validation results above, my conclusion is that a single order polynomial model using the predictors that correspond to columns 3, 4, 7, 8, and 9 will produce the most accurate results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}