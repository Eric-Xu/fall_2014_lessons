{
 "metadata": {
  "name": "",
  "signature": "sha256:d02ceb512660a293a47a438c4706b98ff10d786d9551fac3884ae3df0842a268"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import train_test_split, Bootstrap\n",
      "from sklearn.datasets import make_blobs\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1: Generate some (> 75) random blobs\n",
      "\n",
      "X, y = make_blobs...\n",
      "\n",
      "\n",
      "## Step 2: Plot 'em, with color as a label\n",
      "fig = plt.figure(figsize=(10,8))\n",
      "\n",
      "ax = fig.add_subplot(111)\n",
      "\n",
      "ax.scatter..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "RTFM:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- [DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
      "- [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
      "- [ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main parameters to adjust when using these methods is **n_estimators** and **max_features**. \n",
      "\n",
      "- The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. \n",
      "\n",
      "- The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. \n",
      "\n",
      "Empirical good default values are max_features=n_features for regression problems, and max_features=sqrt(n_features) for classification tasks (where n_features is the number of features in the data)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3: \n",
      "\n",
      "- Create one each of a DecisionTreeClassifier, RandomForestClassifier, ExtraTreesClassifier and object:\n",
      "\n",
      "## Step 4:\n",
      "\n",
      "- Print the Cross Validated Score for each classifier (hint: you don't have to use the fit() or predict() methods() )\n",
      "\n",
      "## Questions:\n",
      "\n",
      "1. Which classifier model has the best score?\n",
      "2. What happens when you change the parameters of the model (e.g. n_estimators)? Does the cross_val_score change significantly?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## DecisionTreeClassifier\n",
      "dt_clf = DecisionTreeClassifier(...)\n",
      "scores = ...\n",
      "print \"DecisionTreeClassifier\", scores.mean()\n",
      "\n",
      "## RandomForestClassifier\n",
      "rf_clf = RandomForestClassifier(...)\n",
      "scores = ...\n",
      "print \"RandomForestClassifier\", scores.mean()\n",
      "\n",
      "## ExtraTreesClassifier\n",
      "extra_trees_clf = ExtraTreesClassifier(...)\n",
      "scores = ...\n",
      "print \"ExtraTreesClassifier\", scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-38-1986030be981>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-1986030be981>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    dt_clf = DecisionTreeClassifier(...)\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 5: \n",
      "\n",
      "- Create test/train splits of the original data set\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(...)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 6:\n",
      "\n",
      "- Fit the training data to the model (call the fit() methods on them)\n",
      "- Create [Confusion Matrixes](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) for each model (hint: you have to run the predict() method)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print metrics.confusion_matrix(...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-40-3832f51ad65e>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-3832f51ad65e>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print metrics.confusion_matrix(...)\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.confusion_matrix(...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-41-aa51ff3734de>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-41-aa51ff3734de>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print metrics.confusion_matrix(...)\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.confusion_matrix(...)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-42-aa51ff3734de>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-aa51ff3734de>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    print metrics.confusion_matrix(...)\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Application to other data sets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have a dataset of chapters from books and plays by specific authors, and their usages of stop words. Let's see how accurately a random forest can predict the author based on stop word usage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "from sklearn.cross_validation import train_test_split, Bootstrap\n",
      "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn import metrics\n",
      "from sklearn import preprocessing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1: Read the data into a DataFrame\n",
      "\n",
      "- \"http://people.stern.nyu.edu/jsimonof/AnalCatData/Data/Comma_separated/authorship.csv\"\n",
      "\n",
      "- Print the columns, print df.head()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in the authorship csv file.\n",
      "authorship = ...\n",
      "print authorship.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-43-f90fcde1e8a3>, line 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-f90fcde1e8a3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    authorship = ...\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: Create a unique list of author names and print it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Setting a list to represent all the authors in the file\n",
      "authors = ...\n",
      "print \"Authors:\", authors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3: \n",
      "\n",
      "Use the LabelEncoder to encode Authors to integers...\n",
      "\n",
      "### Question:\n",
      "\n",
      "1. What does the LabelEncoder do for us? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use LabelEncoder to encode Authors to integers\n",
      "le = preprocessing.LabelEncoder()\n",
      "le.fit(authors)\n",
      "authorship['Author_num'] = le.transform(authorship['Author']) # Actually sets the author's \"number\" or id\n",
      "print authorship['Author_num']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#What are some of the stop words we're looking at?\n",
      "features = list(authorship.columns)\n",
      "\n",
      "features.remove('Author')\n",
      "features.remove('Author_num')\n",
      "print features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4:\n",
      "\n",
      "- Create a random variable column \n",
      "- Create test/train sets using test_train_split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a random variable (random forests work best with a random variable)\n",
      "# and create a test and training set\n",
      "#authorship['random'] = [random.random() for i in range(841)]\n",
      "x, y = authorship[features], authorship.Author_num.values\n",
      "x_train, x_test, y_train, y_test = train_test_split(authorship[features],\n",
      "                                                    authorship.Author_num.values,\n",
      "                                                    test_size=0.4,\n",
      "                                                    random_state=123)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 5:\n",
      "\n",
      "- Create three classifier objects: ExtraTreesClassifier, AdaBoostClassifier, MultinomialNB\n",
      "- Fit training data\n",
      "- Compare cross-validation scores\n",
      "- Print out Confusion Matrixes\n",
      "\n",
      "### Questions:\n",
      "\n",
      "1. Which classifiers perform best with this data? Why is that?\n",
      "2. What adjustments can you make to the classifier object instantiation to change the outcome of the predictions?\n",
      "3. (Similar to Q2) What are the trade-offs between the different models and different input tuning params?\n",
      "4. Create some additional classifiers and compare them"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Compare the results here of random forests, adaboost, and a non-ensembled naive bayes classifier.\n",
      "\n",
      "print ExtraTreesClassifier.__name__, 'results'\n",
      "\n",
      "\n",
      "\n",
      "print AdaBoostClassifier.__name__, 'results'\n",
      "\n",
      "\n",
      "\n",
      "print MultinomialNB.__name__, 'results'\n",
      "\n",
      "\n",
      "## Sometimes a simpler answer is a better approach!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}